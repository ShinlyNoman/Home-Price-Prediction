# -*- coding: utf-8 -*-
"""CSE366 Projec(House Price Prediction).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZAnDE9AzaRPdxcAZxnnl9fVaVOqZ_w4f
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings("ignore")
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error
from sklearn.linear_model import LinearRegression
from sklearn.linear_model import Ridge
from sklearn.linear_model import Lasso
from sklearn.linear_model import ElasticNet
from sklearn.metrics import confusion_matrix, accuracy_score,classification_report
from sklearn.preprocessing import PolynomialFeatures
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestRegressor
import seaborn as sns
from sklearn.model_selection import GridSearchCV
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score,classification_report
from sklearn import metrics
from mlxtend.plotting import plot_confusion_matrix

"""Input DataSet"""

df = pd.read_csv("train.csv")

df.head(10).style.background_gradient(cmap = "viridis")

## getting last five rows
df.tail().style.background_gradient(cmap = "viridis")

df.columns

df.shape

missing=df.isnull().sum()
missing=missing[missing>0]
missing.sort_values(inplace=True)
plt.figure(figsize=(15,8))
missing.plot.bar()

#bins =its divide whole range in max to min by 20 ,and each histogram comprose 20
#kde= only show distribution boundary
#positively skewed
sns.set(rc={'figure.figsize':(12,8)})
sns.displot(df['SalePrice'],kde=False ,bins=20)

df['SalePrice'].describe()

sns.kdeplot(df['SalePrice'])

df.info()

"""**Statically Describing**"""

df.describe()

"""**Visualizing the correlations between numerical and categorical variables By using Seaborn **"""

numeric_features=df.select_dtypes(include=[np.number])
numeric_features.columns

categorical_features=df.select_dtypes(include=[np.object])
categorical_features.columns

"""**Correlation**"""

correlation=numeric_features.corr()
print(correlation['SalePrice'].sort_values(ascending=False),'\n')

#Annot=true -->Note that DataFrames will match on position, not index.
plt.figure(figsize=(15,15))
plt.title("Correlations Between Variables", size=30)
sns.heatmap(df.corr(), annot=True, annot_kws={"fontsize":5}, fmt=".2f", vmin=-1)
plt.show()

"""**Feature Selection:**"""

important_num_cols = list(df.corr()["SalePrice"][(df.corr()["SalePrice"]>0.50) | (df.corr()["SalePrice"]<-0.50)].index)
cat_cols = ["MSZoning", "Utilities","BldgType","Heating","KitchenQual","SaleCondition","LandSlope"]
important_cols = important_num_cols + cat_cols
df = df[important_cols]

"""Visualizing the correlations between numerical variables  After Feature Selection:"""

plt.figure(figsize=(10,10))
plt.title("Correlations Between Variables", size=30)
sns.heatmap(df.corr(), annot=True, annot_kws={"fontsize":5}, fmt=".2f", vmin=-1)
plt.show()

"""**Checking for the missing values:**"""

print("Missing Values by Column")
print("-"*30)
print(df.isna().sum())
print("-"*30)
print("TOTAL MISSING VALUES:",df.isna().sum().sum())

"""Boxplot"""

sns.boxplot(x=df["SalePrice"])

first_quartile=df['SalePrice'].quantile(.25)
third_quartile=df['SalePrice'].quantile(.75)
IQR=first_quartile+third_quartile

new_boundary=third_quartile+ 3*IQR

df.drop(df[df['SalePrice']>new_boundary].index,axis=0,inplace=True)

X = df.drop("SalePrice", axis=1)
y = df["SalePrice"]

X.info()

X = pd.get_dummies(X, columns=cat_cols)

important_num_cols.remove("SalePrice")
scaler = StandardScaler()
X[important_num_cols] = scaler.fit_transform(X[important_num_cols])

X.head(100)

"""**Splitting the data into Train and Test chunks for better evaluation**"""

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=None)

print("Shape of train data  ",X_train.shape, y_train.shape)
print("Shape of test data ", X_test.shape, y_test.shape)

"""**Linear Regression:**"""

from sklearn.linear_model import LinearRegression
lreg = LinearRegression()
lreg.fit(X_train, y_train)
y_pred = lreg.predict(X_test)

def rmse_cv(model):
    rmse = np.sqrt(-cross_val_score(model, X, y, scoring="neg_mean_squared_error", cv=5)).mean()
    return rmse
def evaluation(y,predictions):
    mae = mean_absolute_error(y, predictions)
    mse = mean_squared_error(y, predictions)
    rmse = np.sqrt(mean_squared_error(y, predictions))
    r_squared = r2_score(y, predictions)
    return mae, mse, rmse, r_squared

models = pd.DataFrame(columns=["Model","MAE","MSE","RMSE","R2 Score","RMSE (Cross-Validation)"])

lin_reg = LinearRegression()
lin_reg.fit(X_train, y_train)
predictions = lin_reg.predict(X_test)
mae, mse, rmse, r_squared = evaluation(y_test, predictions)
print("MAE:", mae)
print("MSE:", mse)
print("RMSE:", rmse)
print("R2 Score:", r_squared)
accuracy_train = lreg.score(X_train,y_train)
accuracy_test = lreg.score(X_test, y_test)
print('Accuracy train: ',accuracy_train)
print('Accuracy test: ',accuracy_test)
print("-"*30)
rmse_cross_val = rmse_cv(lin_reg)
print("RMSE Cross-Validation:", rmse_cross_val)

new_row = {"Model": "LinearRegression","MAE": mae, "MSE": mse, "RMSE": rmse, "R2 Score": r_squared, "RMSE (Cross-Validation)": rmse_cross_val}
models = models.append(new_row, ignore_index=True)

# Plotting Scatter graph to show the prediction
# results - 'ytrue' value vs 'y_pred' value
x = np.linspace(0, 1500000, 150000)
plt.plot(x, x, color='k',linestyle="--")
plt.scatter(y_test, y_pred, c = 'green')
plt.xlabel("Price: in $1000's")
plt.ylabel("Predicted value")
plt.title("True value vs predicted value : Linear Regression")
plt.show()

"""**Lasso**"""

lasso = Lasso()
lasso.fit(X_train, y_train)
y_pred1 = lasso.predict(X_test)
predictions = lasso.predict(X_test)

mmae, mse, rmse, r_squared = evaluation(y_test, predictions)
print("MAE:", mae)
print("MSE:", mse)
print("RMSE:", rmse)
print("R2 Score:", r_squared)
print("-"*30)
rmse_cross_val = rmse_cv(lasso)
print("RMSE Cross-Validation:", rmse_cross_val)
new_row = {"Model": "Lasso","MAE": mae, "MSE": mse, "RMSE": rmse, "R2 Score": r_squared, "RMSE (Cross-Validation)": rmse_cross_val}
models = models.append(new_row, ignore_index=True)
accuracy_train = lasso.score(X_train,y_train)
accuracy_test = lasso.score(X_test, y_test)
print('Accuracy train: ',accuracy_train)
print('Accuracy test: ',accuracy_test)

steps = [('poly feature', PolynomialFeatures(degree=2)),
         ('regressor', Lasso(alpha=0.1))]
LR = Pipeline(steps=steps)
LR.fit(X_train, y_train)

Pipeline(steps=[('poly feature', PolynomialFeatures()),
                ('regressor', Lasso(alpha=0.1))])

y_pred = LR.predict(X_test)

x = np.linspace(0, max(np.max(y_test), np.max(y_pred)), 15000)
plt.plot(x, x,color='k',linestyle="--")
plt.scatter(y_test, y_pred, alpha=0.5,c="green");
plt.xlabel('y_true');
plt.ylabel('y_pred');

"""putting together the coefficient and their corresponding variable names"""
lasso_coef = pd.DataFrame()
lasso_coef['Columns'] = X_train.columns
lasso_coef['Coefficient Estimate'] = pd.Series(lasso.coef_)
print(lasso_coef)

"""Lasso Regression will try to add one feature at a time, and if the new feature dosen't improves the fit enough to overweigh penalty term including that feature, then it won't be added.

**Ridge**
"""

ridge = Ridge()
ridge.fit(X_train, y_train)
predictions = ridge.predict(X_test)
mae, mse, rmse, r_squared = evaluation(y_test, predictions)
print("MAE:", mae)
print("MSE:", mse)
print("RMSE:", rmse)
print("R2 Score:", r_squared)
print("-"*30)
rmse_cross_val = rmse_cv(ridge)
print("RMSE Cross-Validation:", rmse_cross_val)
new_row = {"Model": "Ridge","MAE": mae, "MSE": mse, "RMSE": rmse, "R2 Score": r_squared, "RMSE (Cross-Validation)": rmse_cross_val}
models = models.append(new_row, ignore_index=True)

# Calculating the Mean Squared Error
accuracy_train = ridge.score(X_train,y_train)
accuracy_test = ridge.score(X_test, y_test)
print('Accuracy train: ',accuracy_train)
print('Accuracy test: ',accuracy_test)

steps = [('poly feature', PolynomialFeatures(degree=3)),
         ('regressor', Ridge(alpha=0.1))]
LR = Pipeline(steps=steps)
LR.fit(X_train, y_train)

Pipeline(steps=[('poly feature', PolynomialFeatures(degree=3)),
                ('regressor', Ridge(alpha=0.1))])

y_pred = LR.predict(X_test)

x = np.linspace(0, max(np.max(y_test), np.max(y_pred)), 15000)
plt.plot(x, x,color='k',linestyle="--")
plt.scatter(y_test, y_pred, alpha=0.5,c="green");
plt.xlabel('y_true');
plt.ylabel('y_pred');

"""putting together the coefficient and their corresponding variable names"""
ridge_coef = pd.DataFrame()
ridge_coef['Columns'] = X_train.columns
ridge_coef['Coefficient Estimate'] = pd.Series(ridge.coef_)
print(ridge_coef)

"""the above graphs can be misleading in a way that it shows some of the coefficients become zero. In Ridge Regularization, the coefficients can never be 0, they are just too small to observe in above plots.

**Elastic Net Regularization:**
In elastic Net Regularization we added the both terms of L1 and L2 to get the final loss function.
"""

elastic_net = ElasticNet()
elastic_net.fit(X_test, y_test)
predictions = elastic_net.predict(X_test)
mae, mse, rmse, r_squared = evaluation(y_test, predictions)
print("MAE:", mae)
print("MSE:", mse)
print("RMSE:", rmse)
print("R2 Score:", r_squared)
print("-"*30)
rmse_cross_val = rmse_cv(elastic_net)
print("RMSE Cross-Validation:", rmse_cross_val)

new_row = {"Model": "ElasticNet","MAE": mae, "MSE": mse, "RMSE": rmse, "R2 Score": r_squared, "RMSE (Cross-Validation)": rmse_cross_val}
models = models.append(new_row, ignore_index=True)

#Accuracy ELastic
accuracy_train = elastic_net.score(X_train,y_train)
accuracy_test = elastic_net.score(X_test, y_test)
print('Accuracy train: ',accuracy_train)
print('Accuracy test: ',accuracy_test)

steps = [('poly feature', PolynomialFeatures(degree=2)),
         ('regressor', Lasso(alpha=0.1))]
LR = Pipeline(steps=steps)
LR.fit(X_train, y_train)

steps = [('poly feature', PolynomialFeatures(degree=2)),
         ('regressor', ElasticNet(alpha=1, l1_ratio=0.01))]
LR = Pipeline(steps=steps)
LR.fit(X_train, y_train)

y_pred = LR.predict(X_test)
x = np.linspace(0, max(np.max(y_test), np.max(y_pred)), 15000)
plt.plot(x, x,color='k',linestyle="--")
plt.scatter(y_test, y_pred, alpha=0.5,color='green');
plt.xlabel('y_true');
plt.ylabel('y_pred');

"""putting together the coefficient and their corresponding variable names"""
enet_coef = pd.DataFrame()
enet_coef['Columns'] = X_train.columns
enet_coef['Coefficient Estimate'] = pd.Series(elastic_net.coef_)
print(enet_coef)

"""**Logistic Regression**"""

# Logistic Regression
logreg = LogisticRegression()
logreg.fit(X_train, y_train)
Y_pred = logreg.predict(X_test)
acc_log = (logreg.score(X_train, y_train))
acc_log

"""**Decision Tree**"""

# Decision Tree
decision_tree = DecisionTreeClassifier()
decision_tree.fit(X_train, y_train)
Y_pred = decision_tree.predict(X_test)
acc_decision_tree = (decision_tree.score(X_train, y_train))
acc_decision_tree

dt = DecisionTreeClassifier(max_depth=3)
dt.fit(X_train, y_train)

DecisionTreeClassifier(max_depth=3)

from sklearn import tree
text_representation = tree.export_text(dt)
print(text_representation)

y_train_pred = dt.predict(X_train)
y_test_pred = dt.predict(X_test)

"""**Confusion Matrix**"""

from sklearn.metrics import confusion_matrix, accuracy_score,classification_report

print(accuracy_score(y_train, y_train_pred))
confusion_matrix(y_train, y_train_pred)

print (classification_report(y_train, y_train_pred))

"""**Random Forest**"""

random_forest = RandomForestClassifier(n_estimators=100)
random_forest.fit(X_train, y_train)
Y_pred = random_forest.predict(X_test)
random_forest.score(X_train, y_train)
acc_random_forest = (random_forest.score(X_train, y_train) )
acc_random_forest

"""**Support Vector Machine (SVM)**"""

SVM = SVC().fit(X_train, y_train.ravel())
score = SVM.score(X_train, y_train)
print('R_squared:', score)
Y_pred = SVM.predict(X_test)
SVM.score(X_train, y_train)
accuracy_svm = (SVM.score(X_train, y_train) )
print(accuracy_svm)

models.sort_values(by="RMSE (Cross-Validation)")

from sklearn.metrics import max_error, mean_absolute_error, mean_squared_error, r2_score

steps1 = [('poly feature', PolynomialFeatures(degree=2)),
          ('regressor', LinearRegression())]

steps2 = [('poly feature', PolynomialFeatures(degree=3)),
          ('regressor', Ridge(alpha=0.1))]

steps3 = [('poly feature', PolynomialFeatures(degree=2)),
          ('regressor', Lasso(alpha=10))]

steps4 = [('poly feature', PolynomialFeatures(degree=2)),
          ('regressor', ElasticNet(alpha=1, l1_ratio=0.01))]
steps_list = [steps1, steps2, steps3, steps4]
for steps in steps_list:
    LR = Pipeline(steps=steps)
    LR.fit(X_train, y_train)
    y_pred = LR.predict(X_test)
    print('max_abs err: {}, mean_sq err: {}, mean_abs err: {}, R^2 err: {}'.format(max_error(y_test, y_pred),
                                                                                   mean_squared_error(y_test, y_pred),
                                                                                   mean_absolute_error(y_test, y_pred),
                                                                                   r2_score(y_test, y_pred)))